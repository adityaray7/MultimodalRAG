{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-11T04:39:23.460137Z","iopub.status.busy":"2024-07-11T04:39:23.459798Z","iopub.status.idle":"2024-07-11T04:41:54.315870Z","shell.execute_reply":"2024-07-11T04:41:54.314941Z","shell.execute_reply.started":"2024-07-11T04:39:23.460108Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting llama-index\n","  Downloading llama_index-0.10.54-py3-none-any.whl.metadata (11 kB)\n","Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n","  Downloading llama_index_agent_openai-0.2.8-py3-none-any.whl.metadata (729 bytes)\n","Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_cli-0.1.12-py3-none-any.whl.metadata (1.5 kB)\n","Collecting llama-index-core==0.10.53.post1 (from llama-index)\n","  Downloading llama_index_core-0.10.53.post1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n","  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl.metadata (604 bytes)\n","Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n","  Downloading llama_index_indices_managed_llama_cloud-0.2.4-py3-none-any.whl.metadata (3.8 kB)\n","Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n","  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n","Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n","  Downloading llama_index_llms_openai-0.1.25-py3-none-any.whl.metadata (610 bytes)\n","Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n","  Downloading llama_index_multi_modal_llms_openai-0.1.7-py3-none-any.whl.metadata (728 bytes)\n","Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n","  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl.metadata (715 bytes)\n","Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n","Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n","  Downloading llama_index_readers_file-0.1.30-py3-none-any.whl.metadata (5.4 kB)\n","Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n","  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (6.0.1)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.53.post1->llama-index) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (3.9.1)\n","Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (0.6.6)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (1.2.14)\n","Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.53.post1->llama-index)\n","  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (2024.3.1)\n","Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (0.27.0)\n","Collecting llama-cloud<0.0.7,>=0.0.6 (from llama-index-core==0.10.53.post1->llama-index)\n","  Downloading llama_cloud-0.0.6-py3-none-any.whl.metadata (750 bytes)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (1.5.8)\n","Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (3.2.1)\n","Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core==0.10.53.post1->llama-index)\n","  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (1.26.4)\n","Collecting openai>=1.1.0 (from llama-index-core==0.10.53.post1->llama-index)\n","  Downloading openai-1.35.13-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (2.2.1)\n","Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (9.5.0)\n","Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (8.2.3)\n","Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.53.post1->llama-index)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (4.66.4)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (4.9.0)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (0.9.0)\n","Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (1.14.1)\n","Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n","Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\n","Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n","  Downloading llama_parse-0.4.6-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (4.0.3)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n","Requirement already satisfied: pydantic>=1.10 in /opt/conda/lib/python3.10/site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.53.post1->llama-index) (2.5.3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (4.2.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (1.0.5)\n","Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (3.6)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (1.3.0)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.53.post1->llama-index) (0.14.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.53.post1->llama-index) (8.1.7)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.53.post1->llama-index) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.53.post1->llama-index) (2023.12.25)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core==0.10.53.post1->llama-index) (1.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core==0.10.53.post1->llama-index) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core==0.10.53.post1->llama-index) (1.26.18)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.53.post1->llama-index) (3.0.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.53.post1->llama-index) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core==0.10.53.post1->llama-index) (3.21.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.53.post1->llama-index) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.53.post1->llama-index) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.53.post1->llama-index) (2023.4)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core==0.10.53.post1->llama-index) (1.2.0)\n","Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.53.post1->llama-index) (21.3)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.53.post1->llama-index) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.53.post1->llama-index) (2.14.6)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.53.post1->llama-index) (1.16.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.53.post1->llama-index) (3.1.1)\n","Downloading llama_index-0.10.54-py3-none-any.whl (6.8 kB)\n","Downloading llama_index_core-0.10.53.post1-py3-none-any.whl (15.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading llama_index_agent_openai-0.2.8-py3-none-any.whl (13 kB)\n","Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n","Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n","Downloading llama_index_indices_managed_llama_cloud-0.2.4-py3-none-any.whl (9.2 kB)\n","Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_llms_openai-0.1.25-py3-none-any.whl (11 kB)\n","Downloading llama_index_multi_modal_llms_openai-0.1.7-py3-none-any.whl (5.9 kB)\n","Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n","Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n","Downloading llama_index_readers_file-0.1.30-py3-none-any.whl (38 kB)\n","Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n","Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n","Downloading llama_cloud-0.0.6-py3-none-any.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_parse-0.4.6-py3-none-any.whl (9.1 kB)\n","Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.35.13-py3-none-any.whl (328 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: striprtf, dirtyjson, nltk, beautifulsoup4, tiktoken, openai, llama-cloud, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.4\n","    Uninstalling nltk-3.2.4:\n","      Successfully uninstalled nltk-3.2.4\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.12.2\n","    Uninstalling beautifulsoup4-4.12.2:\n","      Successfully uninstalled beautifulsoup4-4.12.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\n","spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed beautifulsoup4-4.12.3 dirtyjson-1.0.8 llama-cloud-0.0.6 llama-index-0.10.54 llama-index-agent-openai-0.2.8 llama-index-cli-0.1.12 llama-index-core-0.10.53.post1 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.2.4 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.25 llama-index-multi-modal-llms-openai-0.1.7 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.30 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.6 nltk-3.8.1 openai-1.35.13 striprtf-0.0.26 tiktoken-0.7.0\n","Requirement already satisfied: llama-index-core in /opt/conda/lib/python3.10/site-packages (0.10.53.post1)\n","Requirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (6.0.1)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (3.9.1)\n","Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (0.6.6)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (2024.3.1)\n","Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (0.27.0)\n","Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (0.0.6)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (1.5.8)\n","Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (3.2.1)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (3.8.1)\n","Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (1.26.4)\n","Requirement already satisfied: openai>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (1.35.13)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (2.2.1)\n","Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (9.5.0)\n","Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (8.2.3)\n","Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (0.7.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (4.66.4)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (4.9.0)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (0.9.0)\n","Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core) (1.14.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (4.0.3)\n","Requirement already satisfied: pydantic>=1.10 in /opt/conda/lib/python3.10/site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core) (2.5.3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core) (4.2.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core) (1.0.5)\n","Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core) (3.6)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core) (1.3.0)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (8.1.7)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (2023.12.25)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core) (1.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core) (1.26.18)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.0.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core) (3.21.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core) (2023.4)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core) (1.2.0)\n","Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (21.3)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core) (2.14.6)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core) (1.16.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (3.1.1)\n","Collecting llama-index-llms-anthropic\n","  Downloading llama_index_llms_anthropic-0.1.15-py3-none-any.whl.metadata (690 bytes)\n","Collecting llama-index-multi-modal-llms-anthropic\n","  Downloading llama_index_multi_modal_llms_anthropic-0.1.4-py3-none-any.whl.metadata (674 bytes)\n","Collecting anthropic<0.29.0,>=0.26.2 (from llama-index-llms-anthropic)\n","  Downloading anthropic-0.28.1-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-llms-anthropic) (0.10.53.post1)\n","INFO: pip is looking at multiple versions of llama-index-multi-modal-llms-anthropic to determine which version is compatible with other requirements. This could take a while.\n","Collecting llama-index-multi-modal-llms-anthropic\n","  Downloading llama_index_multi_modal_llms_anthropic-0.1.3-py3-none-any.whl.metadata (666 bytes)\n","  Downloading llama_index_multi_modal_llms_anthropic-0.1.2-py3-none-any.whl.metadata (666 bytes)\n","  Downloading llama_index_multi_modal_llms_anthropic-0.1.1-py3-none-any.whl.metadata (717 bytes)\n","  Downloading llama_index_multi_modal_llms_anthropic-0.1.0-py3-none-any.whl.metadata (666 bytes)\n","Collecting llama-index-llms-anthropic\n","  Downloading llama_index_llms_anthropic-0.1.14-py3-none-any.whl.metadata (690 bytes)\n","INFO: pip is still looking at multiple versions of llama-index-multi-modal-llms-anthropic to determine which version is compatible with other requirements. This could take a while.\n","  Downloading llama_index_llms_anthropic-0.1.13-py3-none-any.whl.metadata (639 bytes)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading llama_index_llms_anthropic-0.1.12-py3-none-any.whl.metadata (639 bytes)\n","  Downloading llama_index_llms_anthropic-0.1.11-py3-none-any.whl.metadata (639 bytes)\n","Collecting anthropic<0.24.0,>=0.23.1 (from llama-index-llms-anthropic)\n","  Downloading anthropic-0.23.1-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (4.2.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (0.27.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (2.5.3)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (1.3.0)\n","Requirement already satisfied: tokenizers>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (0.19.1)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (4.9.0)\n","Requirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (6.0.1)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (3.9.1)\n","Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (0.6.6)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (2024.3.1)\n","Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (0.0.6)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.5.8)\n","Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (3.2.1)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (3.8.1)\n","Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.26.4)\n","Requirement already satisfied: openai>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.35.13)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (2.2.1)\n","Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (9.5.0)\n","Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (8.2.3)\n","Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (0.7.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (4.66.4)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (0.9.0)\n","Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.14.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (4.0.3)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (3.6)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (1.2.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (0.14.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (8.1.7)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (2023.12.25)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (2.14.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.26.18)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (3.0.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.13.0->anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (0.23.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (3.21.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (2023.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (3.13.1)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (21.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-anthropic) (1.16.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic) (3.1.1)\n","Downloading llama_index_llms_anthropic-0.1.11-py3-none-any.whl (6.1 kB)\n","Downloading llama_index_multi_modal_llms_anthropic-0.1.4-py3-none-any.whl (5.8 kB)\n","Downloading anthropic-0.23.1-py3-none-any.whl (869 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.1/869.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: anthropic, llama-index-multi-modal-llms-anthropic, llama-index-llms-anthropic\n","Successfully installed anthropic-0.23.1 llama-index-llms-anthropic-0.1.11 llama-index-multi-modal-llms-anthropic-0.1.4\n","Collecting llama-index-embeddings-huggingface\n","  Downloading llama_index_embeddings_huggingface-0.2.2-py3-none-any.whl.metadata (769 bytes)\n","Requirement already satisfied: huggingface-hub>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.23.2)\n","Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-huggingface) (0.10.53.post1)\n","Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n","  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.3.1)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.9.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.1)\n","Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n","  Downloading minijinja-2.0.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.8 kB)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.25)\n","Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.6)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.8)\n","Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.27.0)\n","Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.0.6)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.5.8)\n","Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.2.1)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.8.1)\n","Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.26.4)\n","Requirement already satisfied: openai>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.35.13)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.2.1)\n","Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (9.5.0)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.2.3)\n","Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.7.0)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.9.0)\n","Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.14.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.41.2)\n","Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.2)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.2.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.11.4)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\n","Requirement already satisfied: pydantic>=1.10 in /opt/conda/lib/python3.10/site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.5.3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (4.2.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.5)\n","Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.6)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.3.0)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.14.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.1.7)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2023.12.25)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.26.18)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.0.3)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.12.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.2)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.21.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2023.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.2.0)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.14.6)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.3)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n","Downloading llama_index_embeddings_huggingface-0.2.2-py3-none-any.whl (7.2 kB)\n","Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading minijinja-2.0.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (853 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.2/853.2 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: minijinja, sentence-transformers, llama-index-embeddings-huggingface\n","Successfully installed llama-index-embeddings-huggingface-0.2.2 minijinja-2.0.1 sentence-transformers-3.0.1\n","Requirement already satisfied: llama-parse in /opt/conda/lib/python3.10/site-packages (0.4.6)\n","Requirement already satisfied: llama-index-core>=0.10.29 in /opt/conda/lib/python3.10/site-packages (from llama-parse) (0.10.53.post1)\n","Requirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (6.0.1)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.10.29->llama-parse) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (3.9.1)\n","Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (0.6.6)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (2024.3.1)\n","Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (0.27.0)\n","Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (0.0.6)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (1.5.8)\n","Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (3.2.1)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (3.8.1)\n","Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (1.26.4)\n","Requirement already satisfied: openai>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (1.35.13)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (2.2.1)\n","Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (9.5.0)\n","Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (8.2.3)\n","Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (0.7.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (4.66.4)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (4.9.0)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (0.9.0)\n","Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core>=0.10.29->llama-parse) (1.14.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.29->llama-parse) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.29->llama-parse) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.29->llama-parse) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.29->llama-parse) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.29->llama-parse) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.10.29->llama-parse) (4.0.3)\n","Requirement already satisfied: pydantic>=1.10 in /opt/conda/lib/python3.10/site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core>=0.10.29->llama-parse) (2.5.3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core>=0.10.29->llama-parse) (4.2.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core>=0.10.29->llama-parse) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core>=0.10.29->llama-parse) (1.0.5)\n","Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core>=0.10.29->llama-parse) (3.6)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core>=0.10.29->llama-parse) (1.3.0)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core>=0.10.29->llama-parse) (0.14.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core>=0.10.29->llama-parse) (8.1.7)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core>=0.10.29->llama-parse) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core>=0.10.29->llama-parse) (2023.12.25)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core>=0.10.29->llama-parse) (1.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core>=0.10.29->llama-parse) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core>=0.10.29->llama-parse) (1.26.18)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.10.29->llama-parse) (3.0.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.10.29->llama-parse) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core>=0.10.29->llama-parse) (3.21.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core>=0.10.29->llama-parse) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core>=0.10.29->llama-parse) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core>=0.10.29->llama-parse) (2023.4)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core>=0.10.29->llama-parse) (1.2.0)\n","Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.10.29->llama-parse) (21.3)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core>=0.10.29->llama-parse) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core>=0.10.29->llama-parse) (2.14.6)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core>=0.10.29->llama-parse) (1.16.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.10.29->llama-parse) (3.1.1)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.43.1\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n","Collecting pdfplumber\n","  Downloading pdfplumber-0.11.2-py3-none-any.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n","Collecting pdfminer.six==20231228 (from pdfplumber)\n","  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (9.5.0)\n","Collecting pypdfium2>=4.18.0 (from pdfplumber)\n","  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n","Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (41.0.7)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n","Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n","Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading pdfplumber-0.11.2-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdfium2, faiss-cpu, pdfminer.six, pdfplumber\n","Successfully installed faiss-cpu-1.8.0.post1 pdfminer.six-20231228 pdfplumber-0.11.2 pypdfium2-4.30.0\n","Collecting langchain\n","  Downloading langchain-0.2.7-py3-none-any.whl.metadata (6.9 kB)\n","Collecting langchain_openai\n","  Downloading langchain_openai-0.1.15-py3-none-any.whl.metadata (2.5 kB)\n","Collecting langchain_chroma\n","  Downloading langchain_chroma-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n","Collecting langchain_community\n","  Downloading langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n","Collecting langchain-core<0.3.0,>=0.2.12 (from langchain)\n","  Downloading langchain_core-0.2.13-py3-none-any.whl.metadata (6.0 kB)\n","Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n","  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.85-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n","Requirement already satisfied: openai<2.0.0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from langchain_openai) (1.35.13)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /opt/conda/lib/python3.10/site-packages (from langchain_openai) (0.7.0)\n","Collecting chromadb<0.6.0,>=0.4.0 (from langchain_chroma)\n","  Downloading chromadb-0.5.4-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: fastapi<1,>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from langchain_chroma) (0.108.0)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.6)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Collecting build>=1.0.3 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n","Collecting chroma-hnswlib==0.7.5 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading chroma_hnswlib-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n","Requirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.25.0)\n","Collecting posthog>=2.4.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.9.0)\n","Collecting onnxruntime>=1.14.1 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.22.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.22.0)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.22.0)\n","Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.19.1)\n","Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.66.4)\n","Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (7.4.0)\n","Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (6.1.1)\n","Requirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.59.3)\n","Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n","Requirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.9.0)\n","Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Collecting orjson>=3.9.12 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: httpx>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.27.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n","Requirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.32.0.post1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (1.33)\n","Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.12->langchain)\n","  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.2.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.9.0)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.2.0)\n","Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.0.1)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain) (2.4)\n","Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.9.0.post0)\n","Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.26.1)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.7.0)\n","Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.2.2)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (23.5.26)\n","Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.20.3)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.12.1)\n","Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.2.14)\n","Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (6.11.0)\n","Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.2.1)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.62.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.22.0)\n","Requirement already satisfied: opentelemetry-proto==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.22.0)\n","Collecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl.metadata (1.9 kB)\n","Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl.metadata (6.1 kB)\n","Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (69.0.3)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.14.1)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n","Collecting opentelemetry-api>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_api-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n","INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\n","Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\n","Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n","Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata (2.1 kB)\n","Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata (6.1 kB)\n","Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\n","Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl.metadata (2.1 kB)\n","Collecting opentelemetry-instrumentation==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl.metadata (5.9 kB)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.43b0)\n","Collecting opentelemetry-util-http==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl.metadata (2.5 kB)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.23.2)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (8.1.7)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n","Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.0.0)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.19.0)\n","Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.21.0)\n","Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (12.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.9)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2024.3.1)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.17.0)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.5.1)\n","Downloading langchain-0.2.7-py3-none-any.whl (983 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.6/983.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading langchain_openai-0.1.15-py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_chroma-0.1.2-py3-none-any.whl (9.3 kB)\n","Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading chromadb-0.5.4-py3-none-any.whl (581 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.4/581.4 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chroma_hnswlib-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.2.13-py3-none-any.whl (357 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.9/357.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.85-py3-none-any.whl (127 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\n","Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl (11 kB)\n","Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl (14 kB)\n","Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl (28 kB)\n","Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl (6.9 kB)\n","Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n","Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=68bdef0d2afc799e3f3b191b1eabbfc51ae72537adcc0f1034ac2f20b716148e\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built pypika\n","Installing collected packages: pypika, monotonic, mmh3, pyproject_hooks, packaging, orjson, opentelemetry-util-http, humanfriendly, chroma-hnswlib, bcrypt, asgiref, posthog, coloredlogs, build, opentelemetry-instrumentation, onnxruntime, langsmith, kubernetes, opentelemetry-instrumentation-asgi, langchain-core, opentelemetry-instrumentation-fastapi, langchain-text-splitters, langchain_openai, langchain, chromadb, langchain_community, langchain_chroma\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: orjson\n","    Found existing installation: orjson 3.9.10\n","    Uninstalling orjson-3.9.10:\n","      Successfully uninstalled orjson-3.9.10\n","  Attempting uninstall: kubernetes\n","    Found existing installation: kubernetes 26.1.0\n","    Uninstalling kubernetes-26.1.0:\n","      Successfully uninstalled kubernetes-26.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.4.1 requires cubinlinker, which is not installed.\n","cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.4.1 requires ptxcompiler, which is not installed.\n","cuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","keras-cv 0.9.0 requires keras-core, which is not installed.\n","keras-nlp 0.12.1 requires keras-core, which is not installed.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\n","cudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n","distributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n","jupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n","kfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 30.1.0 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n","rapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n","rapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\n","spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed asgiref-3.8.1 bcrypt-4.1.3 build-1.2.1 chroma-hnswlib-0.7.5 chromadb-0.5.4 coloredlogs-15.0.1 humanfriendly-10.0 kubernetes-30.1.0 langchain-0.2.7 langchain-core-0.2.13 langchain-text-splitters-0.2.2 langchain_chroma-0.1.2 langchain_community-0.2.7 langchain_openai-0.1.15 langsmith-0.1.85 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.18.1 opentelemetry-instrumentation-0.43b0 opentelemetry-instrumentation-asgi-0.43b0 opentelemetry-instrumentation-fastapi-0.43b0 opentelemetry-util-http-0.43b0 orjson-3.10.6 packaging-24.1 posthog-3.5.0 pypika-0.48.9 pyproject_hooks-1.1.0\n"]}],"source":["!pip install llama-index\n","!pip install llama-index-core\n","!pip install llama-index-llms-anthropic llama-index-multi-modal-llms-anthropic\n","!pip install llama-index-embeddings-huggingface\n","!pip install llama-parse\n","!pip install bitsandbytes\n","!pip install accelerate faiss-cpu pdfplumber\n","!pip install langchain langchain_openai langchain_chroma langchain_community"]},{"cell_type":"markdown","metadata":{},"source":["# **Initializing**"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T04:41:54.318109Z","iopub.status.busy":"2024-07-11T04:41:54.317803Z","iopub.status.idle":"2024-07-11T04:41:58.353601Z","shell.execute_reply":"2024-07-11T04:41:58.352405Z","shell.execute_reply.started":"2024-07-11T04:41:54.318081Z"},"trusted":true},"outputs":[],"source":["# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n","import nest_asyncio\n","nest_asyncio.apply()\n","from openai import AzureOpenAI\n","import os\n","import numpy as np\n","import os\n","from pathlib import Path\n","from llama_index.readers.file import PDFReader\n","import json\n","from langchain_openai import AzureOpenAIEmbeddings,AzureChatOpenAI\n","\n","\n","# API access to llama-cloud\n","os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"\"\n","\n","# Using Anthropic API for embeddings/LLMs\n","os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n","os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\"\n","\n","llm = AzureChatOpenAI(\n","    azure_deployment=\"\",\n","    api_version=\"\",\n","    temperature=0\n",")\n","\n","embeddings_model = AzureOpenAIEmbeddings(\n","    model = '',\n","    openai_api_version=\"\",\n",")\n","\n","def get_query(messages):\n","    response = llm.invoke(messages)\n","    return response.content\n","\n","def get_embedding(text, model=\"text-embedding3\"):\n","   text = text.replace(\"\\n\", \" \")\n","   return embeddings_model.embed_query(text)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T04:41:58.355948Z","iopub.status.busy":"2024-07-11T04:41:58.355274Z","iopub.status.idle":"2024-07-11T04:41:59.363101Z","shell.execute_reply":"2024-07-11T04:41:59.362237Z","shell.execute_reply.started":"2024-07-11T04:41:58.355906Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Hello! How can I assist you today?'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["get_query(\"hello\")"]},{"cell_type":"markdown","metadata":{},"source":["# Multimodal vision "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:01:14.161805Z","iopub.status.busy":"2024-07-10T09:01:14.160961Z","iopub.status.idle":"2024-07-10T09:06:31.780035Z","shell.execute_reply":"2024-07-10T09:06:31.779243Z","shell.execute_reply.started":"2024-07-10T09:01:14.161772Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a08b199a0fc645beb610db24a1779955","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/3.22k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b61b0033f36a42deaf00c97e17a7d759","version_major":2,"version_minor":0},"text/plain":["tokenization_chatglm.py:   0%|          | 0.00/17.5k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/THUDM/glm-4v-9b:\n","- tokenization_chatglm.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3f5a87ac143471aac1ef5d78d000732","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/2.62M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"850a78ab986240069f346750a9dfe0b4","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8864f40157694d7fbf80117fcdf6b05a","version_major":2,"version_minor":0},"text/plain":["configuration_chatglm.py:   0%|          | 0.00/2.57k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/THUDM/glm-4v-9b:\n","- configuration_chatglm.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b67a4d8c3d2f4b75b336e4f69fccbb7d","version_major":2,"version_minor":0},"text/plain":["modeling_chatglm.py:   0%|          | 0.00/68.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"101cb3515b8d40e79b1b4aa822fb64b4","version_major":2,"version_minor":0},"text/plain":["visual.py:   0%|          | 0.00/6.79k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/THUDM/glm-4v-9b:\n","- visual.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","A new version of the following files was downloaded from https://huggingface.co/THUDM/glm-4v-9b:\n","- modeling_chatglm.py\n","- visual.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fee15c0723fa4bc9ad3162ad3b138078","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/111k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"afbc583b16cd4eb7b3d15d57cc0cc3d0","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/15 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54b60b3842ee4741a3f46ae13bc4457a","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00015.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e0fa9b41a144801990e540d41c39ff8","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5154aaccac094651b5116458a2d8453a","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00015.safetensors:   0%|          | 0.00/1.97G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61f88330d46242e38a3773eae42a03f2","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00015.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb4ac982b3d14e76b4482bbac859c0fa","version_major":2,"version_minor":0},"text/plain":["model-00005-of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9f23d00f33d42bfba5dceb492a90b58","version_major":2,"version_minor":0},"text/plain":["model-00006-of-00015.safetensors:   0%|          | 0.00/1.97G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7cdc20b01294f89be817657f1f7b1ef","version_major":2,"version_minor":0},"text/plain":["model-00007-of-00015.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7cec3b368e2b41fc863391846e29afbd","version_major":2,"version_minor":0},"text/plain":["model-00008-of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e6c6a8c51f34a838ba7b0ccb861fbd3","version_major":2,"version_minor":0},"text/plain":["model-00009-of-00015.safetensors:   0%|          | 0.00/1.97G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad69d9db6b034e15afa0e1693d259d6c","version_major":2,"version_minor":0},"text/plain":["model-00010-of-00015.safetensors:   0%|          | 0.00/1.97G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76ea1a92e4a64df8b817c339de1bf568","version_major":2,"version_minor":0},"text/plain":["model-00011-of-00015.safetensors:   0%|          | 0.00/1.96G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9ae1375f26a435fbb058f1f19375cec","version_major":2,"version_minor":0},"text/plain":["model-00012-of-00015.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ecd15d81b254c7fb48441a8aef3021a","version_major":2,"version_minor":0},"text/plain":["model-00013-of-00015.safetensors:   0%|          | 0.00/1.96G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf0b2e97f22f404286f740f96a87484e","version_major":2,"version_minor":0},"text/plain":["model-00014-of-00015.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d400ee5809d84e7a93726de9daa65105","version_major":2,"version_minor":0},"text/plain":["model-00015-of-00015.safetensors:   0%|          | 0.00/811M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c39968012157424faa5c3979fd1ec8fa","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab0a7d5da6f74d0aa84a31b42ec735f1","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/205 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","from PIL import Image\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","device = \"cuda\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"THUDM/glm-4v-9b\", trust_remote_code=True)\n","\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"THUDM/glm-4v-9b\",\n","    torch_dtype=torch.float16,\n","    load_in_4bit=True,\n","    low_cpu_mem_usage=True,\n","    trust_remote_code=True\n",").eval()\n","\n","# query = 'Analyze this graph' \n","# image = Image.open(\"/kaggle/input/utilss/1.png\").convert('RGB')\n","# inputs = tokenizer.apply_chat_template([{\"role\": \"user\", \"image\": image, \"content\": query}],\n","#                                        add_generation_prompt=True, tokenize=True, return_tensors=\"pt\",\n","#                                        return_dict=True).to(\"cuda\")  # chat mode\n","\n","# gen_kwargs = {\"max_length\": 1024, \"do_sample\": True, \"top_k\": 1}\n","# with torch.no_grad():\n","#     outputs = model.generate(**inputs, **gen_kwargs)\n","#     outputs = outputs[:, inputs['input_ids'].shape[1]:]\n","#     print(tokenizer.decode(outputs[0]))"]},{"cell_type":"markdown","metadata":{},"source":["# **Parsing the pdf**"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Parse the text (using sentence splitter)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from pathlib import Path\n","from llama_index.readers.file import PDFReader\n","from llama_index.core.response.notebook_utils import display_source_node\n","import json\n","from llama_index.core import Document\n","from llama_index.core.node_parser import SentenceSplitter\n","from llama_index.core.schema import IndexNode,NodeRelationship\n","from faiss import IndexFlatIP\n","\n","loader = PDFReader()\n","docs0 = loader.load_data(file=Path(\"/kaggle/input/utilss/a.pdf\"))\n","\n","doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n","docs = [Document(text=doc_text)]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["node_parser = SentenceSplitter(chunk_size=512)\n","\n","text_base_nodes = node_parser.get_nodes_from_documents(docs)\n","# set node ids to be a constant\n","for idx, node in enumerate(text_base_nodes):\n","    node.id_ = f\"node-{idx}\"\n","\n","sub_chunk_sizes = [64, 128, 256]\n","sub_node_parsers = [\n","    SentenceSplitter(chunk_size=c, chunk_overlap=20) for c in sub_chunk_sizes\n","]\n","\n","text_all_nodes = []\n","for base_node in text_base_nodes:\n","    for n in sub_node_parsers:\n","        sub_nodes = n.get_nodes_from_documents([base_node])\n","        sub_inodes = [\n","            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n","        ]\n","        text_all_nodes.extend(sub_inodes)\n","\n","    # also add original node to node\n","    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n","    text_all_nodes.append(original_node)\n","    \n","text_all_nodes_dict = {n.node_id: n for n in text_all_nodes}\n","\n"," # Step 1: Compute embeddings for all nodes\n","text_embeddings = []\n","text_node_ids = []\n","for node_id, node in text_all_nodes_dict.items():\n","    embedding = get_embedding(node.text) \n","    text_embeddings.append(embedding)\n","    text_node_ids.append(node_id)\n","\n","# Convert embeddings to numpy array\n","text_embeddings = np.array(text_embeddings)\n","\n","# Initialize FAISS index\n","text_index = IndexFlatIP(text_embeddings.shape[1])\n","text_index.add(text_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from collections import Counter\n","\n","def text_query_engine(query, text_all_nodes_dict, k=5):\n","    # Step 2: Compute embedding for the query string\n","    query_embedding = get_embedding(query)  # Replace with your actual embedding function\n","\n","    # Search for top k similar nodes\n","    D, I = text_index.search(np.array([query_embedding]), k)\n","\n","    # Step 3: Retrieve base nodes and count their occurrences\n","    text_base_node_ids = []\n","    for idx in I[0]:\n","        similar_node_id = text_node_ids[idx]\n","        similar_node = text_all_nodes_dict.get(similar_node_id)\n","\n","        if similar_node and NodeRelationship.SOURCE in similar_node.relationships:\n","            base_node_id = similar_node.relationships[NodeRelationship.SOURCE].node_id\n","            text_base_node_ids.append(base_node_id)\n","        elif similar_node:\n","            text_base_node_ids.append(similar_node.node_id)  # If no SOURCE relationship, consider the node itself\n","\n","    if text_base_node_ids:\n","        # Find the two most common base nodes among the top k similar nodes\n","        most_common_base_nodes = Counter(text_base_node_ids).most_common(2)\n","        top_base_nodes = [text_all_nodes_dict.get(node_id) for node_id, _ in most_common_base_nodes]\n","        l =[]\n","        for z in top_base_nodes:\n","            l.append(z.node_id)\n","        print(l)\n","        return top_base_nodes\n","\n","Example usage:\n","query_string = \"your query string\"\n","base_nodes = text_query_engine(query_string, text_all_nodes_dict, k=3)\n","if base_nodes:\n","    print(f\"Most Similar Base Node: {base_node.node_id for base_node in base_nodes}\")\n","else:\n","    print(f\"No similar base node found for query: '{query_string}'\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Get tables and images"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:07:13.866874Z","iopub.status.busy":"2024-07-10T09:07:13.865809Z","iopub.status.idle":"2024-07-10T09:07:17.335377Z","shell.execute_reply":"2024-07-10T09:07:17.334402Z","shell.execute_reply.started":"2024-07-10T09:07:13.866840Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Started parsing the file under job_id cac11eca-805a-464a-b900-5174f3dfd367\n"]},{"data":{"text/plain":["15"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from llama_index.core import Settings\n","\n","# Settings.llm = llm\n","# Settings.embed_model = embeddings\n","from llama_parse import LlamaParse\n","\n","parser = LlamaParse(verbose=True)\n","json_objs = parser.get_json_result(\"/kaggle/input/utilss/a.pdf\")\n","json_list = json_objs[0][\"pages\"]\n","len(json_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from llama_index.core.schema import TextNode\n","from typing import List\n","\n","\n","def get_text_nodes(json_list: List[dict]):\n","    text_nodes = []\n","    for idx, page in enumerate(json_list):\n","        text_node = TextNode(\n","            text=page[\"text\"],\n","            metadata={\n","                \"page\": page[\"page\"]\n","            }\n","        )\n","        text_nodes.append(text_node)\n","    return text_nodes\n","text_nodes = get_text_nodes(json_list)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# call get_images on parser, convert to ImageDocuments\n","!mkdir images\n","\n","from llama_index.core.schema import ImageDocument\n","from llama_index.multi_modal_llms.anthropic import AnthropicMultiModal\n","\n","def get_image_text_nodes(json_objs: List[dict]):\n","    \"\"\"Extract out text from images using a multimodal model.\"\"\"\n","    anthropic_mm_llm = AnthropicMultiModal(max_tokens=300)\n","    image_dicts = parser.get_images(json_objs, download_path=\"images\")\n","    image_documents = []\n","    img_text_nodes = []\n","    \n","    for image_dict in image_dicts:\n","        image_doc = ImageDocument(image_path=image_dict[\"path\"])\n","        image_doc = Image.open(image_doc.image_path).convert('RGB')\n","\n","        \n","        \n","#         response = anthropic_mm_llm.complete(\n","#             prompt=\"Describe the images as an alternative text\",\n","#             image_documents=[image_doc],\n","#         )\n","        \n","        \n","        prompt = 'Analyze the graph if any or return the explanation of the image'\n","        inputs = tokenizer.apply_chat_template([{\"role\": \"user\", \"image\": image_doc, \"content\": prompt}],\n","                                               add_generation_prompt=True, tokenize=True, return_tensors=\"pt\",\n","                                               return_dict=True).to(\"cuda\")  # chat mode\n","\n","        gen_kwargs = {\"max_length\": 1024, \"do_sample\": True, \"top_k\": 1}\n","        \n","        with torch.no_grad():\n","            outputs = model.generate(**inputs, **gen_kwargs)\n","            outputs = outputs[:, inputs['input_ids'].shape[1]:]\n","            response = tokenizer.decode(outputs[0])\n","        \n","        \n","        \n","        text_node = TextNode(\n","            text=str(response),\n","            metadata={\"path\": image_dict[\"path\"]}\n","        )\n","        img_text_nodes.append(text_node)\n","    return img_text_nodes\n","\n","image_text_nodes = get_image_text_nodes(json_objs)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","# Convert text nodes to embeddings\n","def convert_nodes_to_embeddings(text_nodes):\n","    embeddings = []\n","    for node in text_nodes:\n","        embedding = get_embedding(node.get_content())\n","        if embedding:\n","            embeddings.append((node, embedding))\n","    return embeddings\n","\n","# Get the embeddings and corresponding nodes\n","node_embeddings = convert_nodes_to_embeddings(image_text_nodes)\n","nodes, embeddings = zip(*node_embeddings)\n","embeddings = np.array(embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import faiss\n","\n","# Define the dimension of your embeddings (for example, 768 for OpenAI embeddings)\n","embedding_dim = len(embeddings[0])\n","\n","# Create a FAISS index\n","index = faiss.IndexFlatL2(embedding_dim)  # Use L2 distance for similarity search\n","index.add(embeddings)  # Add embeddings to the index"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def search_similar_nodes(query, k=2):\n","    # Get the embedding of the query text\n","    query_embedding = get_embedding(query)\n","    if query_embedding is None:\n","        return []\n","\n","    query_embedding = np.array([query_embedding])\n","\n","    # Search for the top k similar embeddings\n","    distances, indices = index.search(query_embedding, k)\n","    print(distances)\n","    \n","    # Retrieve the corresponding nodes\n","    similar_nodes = [nodes[idx] for idx in indices[0]]\n","    for z in similar_nodes:\n","        print(z.get_content())\n","    return similar_nodes\n","\n","# Example usage\n","\n","#for tables and images\n","# query_text = \"Explain the transformers model step by step\"\n","# top_k_similar_nodes = search_similar_nodes(query_text, k=3)\n","\n","# for i, node in enumerate(top_k_similar_nodes):\n","#     print(f\"Node {i+1}:\\nContent: {node.get_content()}\\n, id: {node.id_}\")\n","    \n","#for texts\n","# base_node = text_query_engine(query_text, text_all_nodes_dict, k=3)\n","# if base_node:\n","#     print(f\"Most Similar Base Node: {base_node.get_content()}\")\n","# else:\n","#     print(f\"No similar base node found for query: '{query_string}'\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_prompt(query, similar_nodes,text_base_nodes):\n","    context = \"\"\n","    for text_base_node in text_base_nodes:\n","        if text_base_node is not None:\n","            context+=\"\\n\\n\" + text_base_node.get_content()\n","#     context = context+\"\\n\\n\".join([node.get_content() for node in similar_nodes])\n","    prompt = f\"Use the following context to answer the question:\\n\\n{context}\\n\\nQuestion: {query}\"\n","    return context, prompt\n","\n","def query_engine(query):\n","#     similar_nodes = search_similar_nodes(query)\n","    similar_nodes = None\n","    text_base_nodes = text_query_engine(query, text_all_nodes_dict, k=5)\n","    context, prompt = create_prompt(query, similar_nodes,text_base_nodes)\n","    \n","    messages = [\n","        {\"role\": \"system\", \"content\": prompt},\n","        {\"role\": \"user\", \"content\": query}\n","    ]\n","    \n","    response = get_query(messages)\n","    return context, response"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Example usage\n","query_text = \"What are some empirical evaluations of gated recurrent neural networks on sequence modeling?\"\n","context,response = query_engine(query_text)\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["context"]},{"cell_type":"markdown","metadata":{},"source":["# Testing using ragas"]},{"cell_type":"code","execution_count":56,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-10T09:34:09.940179Z","iopub.status.busy":"2024-07-10T09:34:09.939770Z","iopub.status.idle":"2024-07-10T09:34:25.829561Z","shell.execute_reply":"2024-07-10T09:34:25.828530Z","shell.execute_reply.started":"2024-07-10T09:34:09.940147Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]},{"name":"stdout","output_type":"stream","text":["Collecting pymupdf\n","  Downloading PyMuPDF-1.24.7-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting ragas\n","  Downloading ragas-0.1.10-py3-none-any.whl.metadata (5.2 kB)\n","Collecting PyMuPDFb==1.24.6 (from pymupdf)\n","  Downloading PyMuPDFb-1.24.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from ragas) (1.26.4)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from ragas) (2.19.2)\n","Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (from ragas) (0.7.0)\n","Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (from ragas) (0.2.7)\n","Requirement already satisfied: langchain-core in /opt/conda/lib/python3.10/site-packages (from ragas) (0.2.12)\n","Requirement already satisfied: langchain-community in /opt/conda/lib/python3.10/site-packages (from ragas) (0.2.7)\n","Requirement already satisfied: langchain-openai in /opt/conda/lib/python3.10/site-packages (from ragas) (0.1.14)\n","Requirement already satisfied: openai>1 in /opt/conda/lib/python3.10/site-packages (from ragas) (1.35.12)\n","Collecting pysbd>=0.3.4 (from ragas)\n","  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ragas) (1.5.8)\n","Requirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (from ragas) (1.4.4)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai>1->ragas) (4.2.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>1->ragas) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai>1->ragas) (0.27.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai>1->ragas) (2.5.3)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai>1->ragas) (1.3.0)\n","Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai>1->ragas) (4.66.4)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai>1->ragas) (4.9.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets->ragas) (3.13.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->ragas) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->ragas) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->ragas) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->ragas) (2.2.1)\n","Requirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets->ragas) (2.32.3)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->ragas) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->ragas) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets->ragas) (2024.3.1)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->ragas) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets->ragas) (0.23.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets->ragas) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets->ragas) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain->ragas) (2.0.25)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain->ragas) (4.0.3)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain->ragas) (0.2.2)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain->ragas) (0.1.84)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain->ragas) (8.2.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core->ragas) (1.33)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community->ragas) (0.6.6)\n","Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->ragas) (2023.12.25)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->ragas) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->ragas) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->ragas) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->ragas) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->ragas) (1.3.1)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.6)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>1->ragas) (1.2.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.21.2)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (2.4)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas) (3.10.6)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>1->ragas) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>1->ragas) (2.14.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets->ragas) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets->ragas) (1.26.18)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.0.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->ragas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->ragas) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->ragas) (2023.4)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.16.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.0.0)\n","Downloading PyMuPDF-1.24.7-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading PyMuPDFb-1.24.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading ragas-0.1.10-py3-none-any.whl (91 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.5/91.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pysbd, PyMuPDFb, pymupdf, ragas\n","Successfully installed PyMuPDFb-1.24.6 pymupdf-1.24.7 pysbd-0.3.4 ragas-0.1.10\n"]}],"source":["!pip install pymupdf ragas"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:34:25.832878Z","iopub.status.busy":"2024-07-10T09:34:25.831968Z","iopub.status.idle":"2024-07-10T09:34:29.163098Z","shell.execute_reply":"2024-07-10T09:34:29.162222Z","shell.execute_reply.started":"2024-07-10T09:34:25.832843Z"},"trusted":true},"outputs":[],"source":["from ragas.testset.generator import TestsetGenerator\n","from ragas.testset.evolutions import simple, reasoning, multi_context\n","from langchain_community.document_loaders.pdf import PyMuPDFLoader\n","loader = PyMuPDFLoader('/kaggle/input/utilss/a.pdf')\n","documents = loader.load()\n","\n","\n","# generator with openai models\n","generator_llm = llm\n","critic_llm = llm\n","embeddings = embeddings_model\n","\n","generator = TestsetGenerator.from_langchain(\n","    generator_llm=generator_llm,\n","    critic_llm=critic_llm,\n","    embeddings=embeddings,\n",")"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:34:29.165033Z","iopub.status.busy":"2024-07-10T09:34:29.164375Z","iopub.status.idle":"2024-07-10T09:37:50.663824Z","shell.execute_reply":"2024-07-10T09:37:50.663048Z","shell.execute_reply.started":"2024-07-10T09:34:29.165002Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["embedding nodes:   0%|          | 0/30 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba50600bac4543a69e1703dccb0072f3","version_major":2,"version_minor":0},"text/plain":["Generating:   0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["testset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n"]},{"cell_type":"markdown","metadata":{},"source":["auto merging"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:37:50.665232Z","iopub.status.busy":"2024-07-10T09:37:50.664959Z","iopub.status.idle":"2024-07-10T09:37:50.686676Z","shell.execute_reply":"2024-07-10T09:37:50.685836Z","shell.execute_reply.started":"2024-07-10T09:37:50.665206Z"},"trusted":true},"outputs":[],"source":["testset.to_pandas()\n","questions = testset.to_pandas()[\"question\"].to_list()\n","ground_truth = testset.to_pandas()[\"ground_truth\"].to_list()"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:37:50.687991Z","iopub.status.busy":"2024-07-10T09:37:50.687717Z","iopub.status.idle":"2024-07-10T09:37:50.697928Z","shell.execute_reply":"2024-07-10T09:37:50.696979Z","shell.execute_reply.started":"2024-07-10T09:37:50.687966Z"},"trusted":true},"outputs":[],"source":["from ragas.metrics import (\n","    answer_relevancy,\n","    faithfulness,\n","    context_recall,\n","    context_precision,\n","    answer_relevancy,\n","    answer_similarity\n",")"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:37:50.699348Z","iopub.status.busy":"2024-07-10T09:37:50.699022Z","iopub.status.idle":"2024-07-10T09:38:38.260558Z","shell.execute_reply":"2024-07-10T09:38:38.259782Z","shell.execute_reply.started":"2024-07-10T09:37:50.699323Z"},"trusted":true},"outputs":[],"source":["from datasets import Dataset\n","\n","questions = testset.to_pandas()[\"question\"].to_list()\n","ground_truth = testset.to_pandas()[\"ground_truth\"].to_list()\n","\n","data = {\"question\": [], \"answer\": [], \"contexts\": [], \"ground_truth\": ground_truth}\n","\n","for query in questions:\n","    c,response = text_query_engine(query)\n","    \n","    if c:\n","        data[\"question\"].append(query)\n","        data[\"answer\"].append(response)\n","        data[\"contexts\"].append([c])\n","\n","    \n","dataset = Dataset.from_dict(data)"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:38:38.262392Z","iopub.status.busy":"2024-07-10T09:38:38.261919Z","iopub.status.idle":"2024-07-10T09:38:38.298259Z","shell.execute_reply":"2024-07-10T09:38:38.297410Z","shell.execute_reply.started":"2024-07-10T09:38:38.262354Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>contexts</th>\n","      <th>ground_truth</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>What types of regularization are employed duri...</td>\n","      <td>We employ three types of regularization during...</td>\n","      <td>[\\n\\nandsemanticstructureofthesentences.\\n5 Tr...</td>\n","      <td>We employ three types of regularization during...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>What are some state-of-the-art approaches in s...</td>\n","      <td>Recurrent neural networks, long short-term mem...</td>\n","      <td>[\\n\\ndetail.Nikidesigned,implemented,tunedande...</td>\n","      <td>Recurrent neural networks, long short-term mem...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>What are the dominant sequence transduction mo...</td>\n","      <td>The dominant sequence transduction models are ...</td>\n","      <td>[\\n\\nProvidedproperattributionisprovided,Googl...</td>\n","      <td>The dominant sequence transduction models are ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What types of regularization are employed duri...</td>\n","      <td>We employ three types of regularization during...</td>\n","      <td>[\\n\\nandsemanticstructureofthesentences.\\n5 Tr...</td>\n","      <td>We employ three types of regularization during...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>What are some notable papers and authors in th...</td>\n","      <td>Some notable papers and authors in the field o...</td>\n","      <td>[\\n\\nInformationProcessingSystems,(NIPS),2016....</td>\n","      <td>Some notable papers and authors in the field o...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>What's the title of the paper on empirical eva...</td>\n","      <td>Empirical evaluation of gated recurrent neural...</td>\n","      <td>[\\n\\ndetail.Nikidesigned,implemented,tunedande...</td>\n","      <td>Empirical evaluation of gated recurrent neural...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Which paper evaluates GRNNs for sequence model...</td>\n","      <td>Junyoung Chung, Çaglar Gülçehre, Kyunghyun Ch...</td>\n","      <td>[\\n\\n[4] JianpengCheng,LiDong,andMirellaLapata...</td>\n","      <td>Empirical evaluation of gated recurrent neural...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>How does the Transformer model use multi-head ...</td>\n","      <td>The Transformer model uses multi-head attentio...</td>\n","      <td>[\\n\\nmodel\\nwefounditbeneficialtolinearlyproje...</td>\n","      <td>The Transformer model uses multi-head attentio...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>How do the Transformer model's BLEU scores com...</td>\n","      <td>The Transformer model's BLEU scores are 28.4 f...</td>\n","      <td>[\\n\\nandsemanticstructureofthesentences.\\n5 Tr...</td>\n","      <td>The Transformer model achieves better BLEU sco...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            question  \\\n","0  What types of regularization are employed duri...   \n","1  What are some state-of-the-art approaches in s...   \n","2  What are the dominant sequence transduction mo...   \n","3  What types of regularization are employed duri...   \n","4  What are some notable papers and authors in th...   \n","5  What's the title of the paper on empirical eva...   \n","6  Which paper evaluates GRNNs for sequence model...   \n","7  How does the Transformer model use multi-head ...   \n","8  How do the Transformer model's BLEU scores com...   \n","\n","                                              answer  \\\n","0  We employ three types of regularization during...   \n","1  Recurrent neural networks, long short-term mem...   \n","2  The dominant sequence transduction models are ...   \n","3  We employ three types of regularization during...   \n","4  Some notable papers and authors in the field o...   \n","5  Empirical evaluation of gated recurrent neural...   \n","6  Junyoung Chung, Çaglar Gülçehre, Kyunghyun Ch...   \n","7  The Transformer model uses multi-head attentio...   \n","8  The Transformer model's BLEU scores are 28.4 f...   \n","\n","                                            contexts  \\\n","0  [\\n\\nandsemanticstructureofthesentences.\\n5 Tr...   \n","1  [\\n\\ndetail.Nikidesigned,implemented,tunedande...   \n","2  [\\n\\nProvidedproperattributionisprovided,Googl...   \n","3  [\\n\\nandsemanticstructureofthesentences.\\n5 Tr...   \n","4  [\\n\\nInformationProcessingSystems,(NIPS),2016....   \n","5  [\\n\\ndetail.Nikidesigned,implemented,tunedande...   \n","6  [\\n\\n[4] JianpengCheng,LiDong,andMirellaLapata...   \n","7  [\\n\\nmodel\\nwefounditbeneficialtolinearlyproje...   \n","8  [\\n\\nandsemanticstructureofthesentences.\\n5 Tr...   \n","\n","                                        ground_truth  \n","0  We employ three types of regularization during...  \n","1  Recurrent neural networks, long short-term mem...  \n","2  The dominant sequence transduction models are ...  \n","3  We employ three types of regularization during...  \n","4  Some notable papers and authors in the field o...  \n","5  Empirical evaluation of gated recurrent neural...  \n","6  Empirical evaluation of gated recurrent neural...  \n","7  The Transformer model uses multi-head attentio...  \n","8  The Transformer model achieves better BLEU sco...  "]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["dataset.to_pandas()"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:41:47.546542Z","iopub.status.busy":"2024-07-10T09:41:47.545904Z","iopub.status.idle":"2024-07-10T09:43:05.711304Z","shell.execute_reply":"2024-07-10T09:43:05.710248Z","shell.execute_reply.started":"2024-07-10T09:41:47.546509Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64f612fb520948e7a151b333725c5932","version_major":2,"version_minor":0},"text/plain":["Evaluating:   0%|          | 0/36 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>contexts</th>\n","      <th>ground_truth</th>\n","      <th>answer_relevancy</th>\n","      <th>context_precision</th>\n","      <th>answer_correctness</th>\n","      <th>answer_similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>What types of regularization are employed duri...</td>\n","      <td>We employ three types of regularization during...</td>\n","      <td>[\\n\\nandsemanticstructureofthesentences.\\n5 Tr...</td>\n","      <td>We employ three types of regularization during...</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>0.556921</td>\n","      <td>0.727685</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>What are some state-of-the-art approaches in s...</td>\n","      <td>Recurrent neural networks, long short-term mem...</td>\n","      <td>[\\n\\ndetail.Nikidesigned,implemented,tunedande...</td>\n","      <td>Recurrent neural networks, long short-term mem...</td>\n","      <td>0.889019</td>\n","      <td>1.0</td>\n","      <td>0.861890</td>\n","      <td>0.909099</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>What are the dominant sequence transduction mo...</td>\n","      <td>The dominant sequence transduction models are ...</td>\n","      <td>[\\n\\nProvidedproperattributionisprovided,Googl...</td>\n","      <td>The dominant sequence transduction models are ...</td>\n","      <td>0.803173</td>\n","      <td>1.0</td>\n","      <td>0.742097</td>\n","      <td>0.968388</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What types of regularization are employed duri...</td>\n","      <td>We employ three types of regularization during...</td>\n","      <td>[\\n\\nandsemanticstructureofthesentences.\\n5 Tr...</td>\n","      <td>We employ three types of regularization during...</td>\n","      <td>0.960276</td>\n","      <td>1.0</td>\n","      <td>0.234640</td>\n","      <td>0.938558</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>What are some notable papers and authors in th...</td>\n","      <td>Some notable papers and authors in the field o...</td>\n","      <td>[\\n\\nInformationProcessingSystems,(NIPS),2016....</td>\n","      <td>Some notable papers and authors in the field o...</td>\n","      <td>0.999830</td>\n","      <td>1.0</td>\n","      <td>0.511327</td>\n","      <td>0.891463</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>What's the title of the paper on empirical eva...</td>\n","      <td>Empirical evaluation of gated recurrent neural...</td>\n","      <td>[\\n\\ndetail.Nikidesigned,implemented,tunedande...</td>\n","      <td>Empirical evaluation of gated recurrent neural...</td>\n","      <td>0.527985</td>\n","      <td>1.0</td>\n","      <td>0.981322</td>\n","      <td>0.925288</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Which paper evaluates GRNNs for sequence model...</td>\n","      <td>Junyoung Chung, Çaglar Gülçehre, Kyunghyun Ch...</td>\n","      <td>[\\n\\n[4] JianpengCheng,LiDong,andMirellaLapata...</td>\n","      <td>Empirical evaluation of gated recurrent neural...</td>\n","      <td>0.668493</td>\n","      <td>1.0</td>\n","      <td>0.172388</td>\n","      <td>0.689552</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>How does the Transformer model use multi-head ...</td>\n","      <td>The Transformer model uses multi-head attentio...</td>\n","      <td>[\\n\\nmodel\\nwefounditbeneficialtolinearlyproje...</td>\n","      <td>The Transformer model uses multi-head attentio...</td>\n","      <td>0.894807</td>\n","      <td>1.0</td>\n","      <td>0.667827</td>\n","      <td>0.906602</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>How do the Transformer model's BLEU scores com...</td>\n","      <td>The Transformer model's BLEU scores are 28.4 f...</td>\n","      <td>[\\n\\nandsemanticstructureofthesentences.\\n5 Tr...</td>\n","      <td>The Transformer model achieves better BLEU sco...</td>\n","      <td>0.794582</td>\n","      <td>1.0</td>\n","      <td>0.721302</td>\n","      <td>0.885210</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            question  \\\n","0  What types of regularization are employed duri...   \n","1  What are some state-of-the-art approaches in s...   \n","2  What are the dominant sequence transduction mo...   \n","3  What types of regularization are employed duri...   \n","4  What are some notable papers and authors in th...   \n","5  What's the title of the paper on empirical eva...   \n","6  Which paper evaluates GRNNs for sequence model...   \n","7  How does the Transformer model use multi-head ...   \n","8  How do the Transformer model's BLEU scores com...   \n","\n","                                              answer  \\\n","0  We employ three types of regularization during...   \n","1  Recurrent neural networks, long short-term mem...   \n","2  The dominant sequence transduction models are ...   \n","3  We employ three types of regularization during...   \n","4  Some notable papers and authors in the field o...   \n","5  Empirical evaluation of gated recurrent neural...   \n","6  Junyoung Chung, Çaglar Gülçehre, Kyunghyun Ch...   \n","7  The Transformer model uses multi-head attentio...   \n","8  The Transformer model's BLEU scores are 28.4 f...   \n","\n","                                            contexts  \\\n","0  [\\n\\nandsemanticstructureofthesentences.\\n5 Tr...   \n","1  [\\n\\ndetail.Nikidesigned,implemented,tunedande...   \n","2  [\\n\\nProvidedproperattributionisprovided,Googl...   \n","3  [\\n\\nandsemanticstructureofthesentences.\\n5 Tr...   \n","4  [\\n\\nInformationProcessingSystems,(NIPS),2016....   \n","5  [\\n\\ndetail.Nikidesigned,implemented,tunedande...   \n","6  [\\n\\n[4] JianpengCheng,LiDong,andMirellaLapata...   \n","7  [\\n\\nmodel\\nwefounditbeneficialtolinearlyproje...   \n","8  [\\n\\nandsemanticstructureofthesentences.\\n5 Tr...   \n","\n","                                        ground_truth  answer_relevancy  \\\n","0  We employ three types of regularization during...          0.000000   \n","1  Recurrent neural networks, long short-term mem...          0.889019   \n","2  The dominant sequence transduction models are ...          0.803173   \n","3  We employ three types of regularization during...          0.960276   \n","4  Some notable papers and authors in the field o...          0.999830   \n","5  Empirical evaluation of gated recurrent neural...          0.527985   \n","6  Empirical evaluation of gated recurrent neural...          0.668493   \n","7  The Transformer model uses multi-head attentio...          0.894807   \n","8  The Transformer model achieves better BLEU sco...          0.794582   \n","\n","   context_precision  answer_correctness  answer_similarity  \n","0                1.0            0.556921           0.727685  \n","1                1.0            0.861890           0.909099  \n","2                1.0            0.742097           0.968388  \n","3                1.0            0.234640           0.938558  \n","4                1.0            0.511327           0.891463  \n","5                1.0            0.981322           0.925288  \n","6                1.0            0.172388           0.689552  \n","7                1.0            0.667827           0.906602  \n","8                1.0            0.721302           0.885210  "]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["from ragas import evaluate\n","\n","from ragas.metrics import (\n","    faithfulness,\n","    answer_relevancy,\n","    context_relevancy,\n","    context_recall,\n","    context_precision,\n","    answer_correctness,\n","    answer_similarity,\n","    context_precision\n",")\n","\n","result = evaluate(\n","    dataset = dataset,\n","    llm = llm,\n","    embeddings = embeddings,\n","    metrics=[\n","        answer_relevancy,\n","        context_precision,\n","        answer_correctness,\n","        answer_similarity,\n","    ],\n",")\n","\n","result.to_pandas()\n"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:39:46.037662Z","iopub.status.busy":"2024-07-10T09:39:46.037298Z","iopub.status.idle":"2024-07-10T09:39:46.051914Z","shell.execute_reply":"2024-07-10T09:39:46.050794Z","shell.execute_reply.started":"2024-07-10T09:39:46.037631Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Empirical evaluation of gated recurrent neural networks for sequence modeling.'"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["result.to_pandas()['answer'][5]"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:43:10.019292Z","iopub.status.busy":"2024-07-10T09:43:10.018929Z","iopub.status.idle":"2024-07-10T09:43:10.024429Z","shell.execute_reply":"2024-07-10T09:43:10.023402Z","shell.execute_reply.started":"2024-07-10T09:43:10.019263Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'answer_relevancy': 0.7265, 'context_precision': 1.0000, 'answer_correctness': 0.6055, 'answer_similarity': 0.8713}\n"]}],"source":["print(result)\n"]},{"cell_type":"markdown","metadata":{},"source":["usng both and parent chunk 1024:\n","{'faithfulness': 0.7773, 'answer_relevancy': 0.8276, 'answer_correctness': 0.5453, 'answer_similarity': 0.6732}\n","\n","reduced parent chunk and no images:\n","{'faithfulness': 0.9408, 'answer_relevancy': 0.8530, 'answer_correctness': 0.5791, 'answer_similarity': 0.7451, 'context_recall': 0.6833, 'context_relevancy': 0.0841}\n","\n","{'faithfulness': 0.9248, 'context_precision': 0.8000, 'context_recall': 0.6833, 'context_relevancy': 0.0632}\n","\n","\n","full pipeline:\n","{'faithfulness': 0.7407, 'answer_relevancy': 0.7265, 'context_precision': 1.0000, 'answer_correctness': 0.6055, 'answer_similarity': 0.8713, 'context_recall': 0.9444, 'context_relevancy': 0.0383}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["0.17,1,0.95,s - 0.93, c - 0.61"]},{"cell_type":"markdown","metadata":{},"source":["# Using Recursive retriever\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:12:29.487888Z","iopub.status.busy":"2024-07-10T09:12:29.486945Z","iopub.status.idle":"2024-07-10T09:12:29.633887Z","shell.execute_reply":"2024-07-10T09:12:29.632999Z","shell.execute_reply.started":"2024-07-10T09:12:29.487855Z"},"trusted":true},"outputs":[],"source":["from langchain.retrievers import ParentDocumentRetriever, BM25Retriever, EnsembleRetriever\n","from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain.vectorstores import Chroma\n","from langchain.storage import InMemoryStore\n","import pdfplumber\n","import os"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:49:44.938727Z","iopub.status.busy":"2024-07-10T09:49:44.937809Z","iopub.status.idle":"2024-07-10T09:49:44.956736Z","shell.execute_reply":"2024-07-10T09:49:44.955608Z","shell.execute_reply.started":"2024-07-10T09:49:44.938693Z"},"trusted":true},"outputs":[],"source":["class Document:\n","    def __init__(self, content, metadata=None):\n","        self.page_content = content\n","        self.metadata = metadata if metadata is not None else {}\n","\"\"\"\n","A class is like a blueprint for creating objects. \n","An object is a collection of data (variables) and methods (functions) \n","that act on the data. For example, a Document class can be used \n","to create Document objects, each with its own content and metadata.\n","\"\"\"\n","\n","# Load selected document\n","\n","def get_image_description(image_path):\n","    print(image_path)\n","    image_doc = Image.open(image_path).convert('RGB')\n","#     image_doc = image\n","    prompt = 'Analyze the graph if any or return the explanation of the image in 200 words'\n","    inputs = tokenizer.apply_chat_template([{\"role\": \"user\", \"image\": image_doc, \"content\": prompt}],\n","                                           add_generation_prompt=True, tokenize=True, return_tensors=\"pt\",\n","                                           return_dict=True).to(\"cuda\")  # chat mode\n","\n","    gen_kwargs = {\"max_length\": 1024, \"do_sample\": True, \"top_k\": 1}\n","\n","    with torch.no_grad():\n","        outputs = model.generate(**inputs, **gen_kwargs)\n","        outputs = outputs[:, inputs['input_ids'].shape[1]:]\n","        response = tokenizer.decode(outputs[0])\n","        \n","    return response\n","\n","        \n","\n","def start_image_processing(page):\n","    images_in_page = page.images\n","    page_height = page.height\n","    i=1\n","    for image in images_in_page:\n","        image_bbox = (image['x0'], page_height - image['y1'], image['x1'], page_height - image['y0'])\n","        cropped_page = page.crop(image_bbox)\n","        image_obj = cropped_page.to_image(resolution=400)\n","        page_num = image['page_number']\n","        image_path = f\"/kaggle/working/images_to_parse/{page_num}_{i}.png\"\n","        image_obj.save(f\"/kaggle/working/images_to_parse/{image['page_number']}_{i}.png\")\n","        description = get_image_description(image_path)\n","        i+=1\n","    return description\n","    \n","\n","\n","def load_single_document(file_path):\n","    # Print the start of the document loading process\n","    print(f\"Starting to load document from {file_path}\")\n","    \n","    if os.path.exists(file_path) and file_path.endswith(\".pdf\"):\n","        # Print the filename of the PDF being processed\n","        filename = os.path.basename(file_path)\n","        print(f\"Loading PDF file: {filename}\")\n","        \n","        with pdfplumber.open(file_path) as pdf:\n","            full_text = []\n","            # Print the number of pages in the PDF\n","            print(f\"Number of pages in PDF: {len(pdf.pages)}\")\n","            \n","            for page_number, page in enumerate(pdf.pages, start=1):\n","                page_text = page.extract_text()\n","                \n","                if page.images:\n","                    print(page_number)\n","                    description = start_image_processing(page)\n","                    print(description)\n","                    page_text+=description\n","                    \n","                if page_text:\n","                    full_text.append(page_text)\n","                    \n","                # Print confirmation for each page processed\n","                print(f\"Processed page {page_number}/{len(pdf.pages)}\")\n","            \n","            # Combine all pages' text into one string for the document\n","            document_text = '\\n'.join(full_text)\n","            # Create a Document object with the content and optional metadata\n","            document = Document(content=document_text, metadata={'filename': filename})\n","            # Print that the document has been successfully created\n","            print(f\"Created document for {filename} with {len(full_text)} pages of text.\")\n","    else:\n","        print(f\"File not found or is not a PDF: {file_path}\")\n","        return None\n","    \n","    return document"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:50:43.436787Z","iopub.status.busy":"2024-07-10T09:50:43.436145Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting to load document from /kaggle/input/utilss/a.pdf\n","Loading PDF file: a.pdf\n","Number of pages in PDF: 15\n","Processed page 1/15\n","Processed page 2/15\n","3\n","/kaggle/working/images_to_parse/3_1.png\n"]}],"source":["# Specify the path to the PDF file\n","file_path = '/kaggle/input/utilss/a.pdf'\n","document = load_single_document(file_path) # Load the document\n","docs=[]\n","docs.append(document)\n","\n","# from langchain_community.document_loaders import PyMuPDFLoader\n","# loader = PyMuPDFLoader(\"/kaggle/input/utilss/a.pdf\")\n","# docs = loader.load()"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:32:56.407544Z","iopub.status.busy":"2024-07-10T09:32:56.407153Z","iopub.status.idle":"2024-07-10T09:32:56.459432Z","shell.execute_reply":"2024-07-10T09:32:56.458217Z","shell.execute_reply.started":"2024-07-10T09:32:56.407513Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'vectorstore' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m coll \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241m.\u001b[39mget()  \u001b[38;5;66;03m# dict_keys(['ids', 'embeddings', 'documents', 'metadatas'])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m ids_to_del \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(coll[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n","\u001b[0;31mNameError\u001b[0m: name 'vectorstore' is not defined"]}],"source":["coll = vectorstore.get()  # dict_keys(['ids', 'embeddings', 'documents', 'metadatas'])\n","\n","ids_to_del = []\n","\n","for idx in range(len(coll['ids'])):\n","\n","    id = coll['ids'][idx]\n","    metadata = coll['metadatas'][idx]\n","    ids_to_del.append(id)\n","\n","vectorstore._collection.delete(ids_to_del)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:33:03.886431Z","iopub.status.busy":"2024-07-10T09:33:03.886091Z","iopub.status.idle":"2024-07-10T09:33:14.002407Z","shell.execute_reply":"2024-07-10T09:33:14.001478Z","shell.execute_reply.started":"2024-07-10T09:33:03.886405Z"},"trusted":true},"outputs":[],"source":["# This text splitter is used to create the parent documents\n","parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000,chunk_overlap = 50)\n","\n","# This text splitter is used to create the child documents\n","# It should create documents smaller than the parent\n","child_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap = 20)\n","\n","# The vectorstore to use to index the child chunks\n","vectorstore = Chroma(collection_name=\"return_split_parent_documents\", embedding_function=embeddings_model)\n","\n","# The storage layer for the parent documents\n","store = InMemoryStore()\n","\n","retriever = ParentDocumentRetriever(\n","    vectorstore=vectorstore, \n","    docstore=store, \n","    child_splitter=child_splitter,\n","    parent_splitter=parent_splitter,\n",")\n","\n","retriever.add_documents(docs)"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:33:17.447111Z","iopub.status.busy":"2024-07-10T09:33:17.446360Z","iopub.status.idle":"2024-07-10T09:33:17.702534Z","shell.execute_reply":"2024-07-10T09:33:17.701615Z","shell.execute_reply.started":"2024-07-10T09:33:17.447061Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[Document(metadata={'doc_id': '53a8eec7-fc9e-41f8-848b-80b663b7dd78', 'filename': 'a.pdf'}, page_content='Self-attention,sometimescalledintra-attentionisanattentionmechanismrelatingdifferentpositions\\nofasinglesequenceinordertocomputearepresentationofthesequence. Self-attentionhasbeen\\nusedsuccessfullyinavarietyoftasksincludingreadingcomprehension,abstractivesummarization,\\ntextualentailmentandlearningtask-independentsentencerepresentations[4,27,28,22].'),\n"," Document(metadata={'doc_id': '84a90845-2618-4e14-a9e0-599a5fc338a9', 'filename': 'a.pdf'}, page_content='3.2 Attention\\nAnattentionfunctioncanbedescribedasmappingaqueryandasetofkey-valuepairstoanoutput,\\nwherethequery,keys,values,andoutputareallvectors. Theoutputiscomputedasaweightedsum\\n3\\nScaledDot-ProductAttention Multi-HeadAttention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattentionlayersrunninginparallel.'),\n"," Document(metadata={'doc_id': 'a807e82d-622c-4c9c-8137-ed89efebd893', 'filename': 'a.pdf'}, page_content='attentionandtheparameter-freepositionrepresentationandbecametheotherpersoninvolvedinnearlyevery'),\n"," Document(metadata={'doc_id': '84a90845-2618-4e14-a9e0-599a5fc338a9', 'filename': 'a.pdf'}, page_content='plicative)attention. Dot-productattentionisidenticaltoouralgorithm,exceptforthescalingfactor\\nof √1 . Additiveattentioncomputesthecompatibilityfunctionusingafeed-forwardnetworkwith\\ndk\\nasinglehiddenlayer. Whilethetwoaresimilarintheoreticalcomplexity,dot-productattentionis\\nmuchfasterandmorespace-efficientinpractice,sinceitcanbeimplementedusinghighlyoptimized\\nmatrixmultiplicationcode.')]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["vectorstore.similarity_search(\"what is  attention?\")"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:47:37.767737Z","iopub.status.busy":"2024-07-10T09:47:37.767093Z","iopub.status.idle":"2024-07-10T09:47:38.677512Z","shell.execute_reply":"2024-07-10T09:47:38.676531Z","shell.execute_reply.started":"2024-07-10T09:47:37.767706Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[Document(metadata={'filename': 'a.pdf'}, page_content='3.2 Attention\\nAnattentionfunctioncanbedescribedasmappingaqueryandasetofkey-valuepairstoanoutput,\\nwherethequery,keys,values,andoutputareallvectors. Theoutputiscomputedasaweightedsum\\n3\\nScaledDot-ProductAttention Multi-HeadAttention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattentionlayersrunninginparallel.\\nofthevalues,wheretheweightassignedtoeachvalueiscomputedbyacompatibilityfunctionofthe\\nquerywiththecorrespondingkey.\\n3.2.1 ScaledDot-ProductAttention\\nWecallourparticularattention\"ScaledDot-ProductAttention\"(Figure2). Theinputconsistsof\\nqueriesandkeysofdimensiond k,a√ndvaluesofdimensiond v. Wecomputethedotproductsofthe\\nquerywithallkeys,divideeachby d ,andapplyasoftmaxfunctiontoobtaintheweightsonthe\\nk\\nvalues.\\nInpractice,wecomputetheattentionfunctiononasetofqueriessimultaneously,packedtogether\\nintoamatrixQ. ThekeysandvaluesarealsopackedtogetherintomatricesK andV. Wecompute\\nthematrixofoutputsas:\\nQKT\\nAttention(Q,K,V)=softmax( √ )V (1)\\nd\\nk\\nThetwomostcommonlyusedattentionfunctionsareadditiveattention[2],anddot-product(multi-\\nplicative)attention. Dot-productattentionisidenticaltoouralgorithm,exceptforthescalingfactor\\nof √1 . Additiveattentioncomputesthecompatibilityfunctionusingafeed-forwardnetworkwith\\ndk\\nasinglehiddenlayer. Whilethetwoaresimilarintheoreticalcomplexity,dot-productattentionis\\nmuchfasterandmorespace-efficientinpractice,sinceitcanbeimplementedusinghighlyoptimized\\nmatrixmultiplicationcode.\\nWhileforsmallvaluesofd thetwomechanismsperformsimilarly,additiveattentionoutperforms\\nk\\ndotproductattentionwithoutscalingforlargervaluesofd [3]. Wesuspectthatforlargevaluesof\\nk\\nd ,thedotproductsgrowlargeinmagnitude,pushingthesoftmaxfunctionintoregionswhereithas\\nk\\nextremelysmallgradients4. Tocounteractthiseffect,wescalethedotproductsby √1 .\\ndk\\n3.2.2 Multi-HeadAttention\\nInsteadofperformingasingleattentionfunctionwithd -dimensionalkeys,valuesandqueries,\\nmodel')]"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["retriever.get_relevant_documents(\"explain the Scaled Dot-Product Attention mechanism\")\n"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:33:29.471519Z","iopub.status.busy":"2024-07-10T09:33:29.471100Z","iopub.status.idle":"2024-07-10T09:33:29.478313Z","shell.execute_reply":"2024-07-10T09:33:29.477368Z","shell.execute_reply.started":"2024-07-10T09:33:29.471489Z"},"trusted":true},"outputs":[],"source":["def text_query_engine(query):\n","    prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n","    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n","\n","    {context}\n","\n","    Question: {question}\n","    Answer:\"\"\"\n","    PROMPT = PromptTemplate(\n","        template=prompt_template, input_variables=[\"context\", \"question\"]\n","    )\n","\n","    larger_chunk_relevant_docs =retriever.get_relevant_documents(query)\n","\n","    content = \"\"\n","    for cont in larger_chunk_relevant_docs:\n","        content+='\\n\\n'+cont.page_content\n","\n","    response = llm.invoke(input=PROMPT.format_prompt(\n","        context=larger_chunk_relevant_docs,\n","        question=query\n","    ).text).content\n","    \n","    return content,response\n","    "]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:33:46.827412Z","iopub.status.busy":"2024-07-10T09:33:46.826352Z","iopub.status.idle":"2024-07-10T09:33:49.202821Z","shell.execute_reply":"2024-07-10T09:33:49.201823Z","shell.execute_reply.started":"2024-07-10T09:33:46.827378Z"},"trusted":true},"outputs":[],"source":["content,response = text_query_engine(\"what is attention?\")"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:33:54.326432Z","iopub.status.busy":"2024-07-10T09:33:54.326030Z","iopub.status.idle":"2024-07-10T09:33:54.332663Z","shell.execute_reply":"2024-07-10T09:33:54.331671Z","shell.execute_reply.started":"2024-07-10T09:33:54.326400Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.'"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["response"]},{"cell_type":"markdown","metadata":{},"source":["# Images and tables"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:07:28.397859Z","iopub.status.busy":"2024-07-10T09:07:28.396986Z","iopub.status.idle":"2024-07-10T09:07:29.438921Z","shell.execute_reply":"2024-07-10T09:07:29.437708Z","shell.execute_reply.started":"2024-07-10T09:07:28.397825Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["rmdir: failed to remove '/kaggle/working/images_to_parse': No such file or directory\n"]}],"source":["rmdir \"/kaggle/working/images_to_parse\""]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T09:19:12.712221Z","iopub.status.busy":"2024-07-10T09:19:12.711790Z","iopub.status.idle":"2024-07-10T09:19:20.060351Z","shell.execute_reply":"2024-07-10T09:19:20.059422Z","shell.execute_reply.started":"2024-07-10T09:19:12.712191Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory '/kaggle/working/images_to_parse': File exists\n","3\n","4\n","4\n"]}],"source":["import pdfplumber\n","\n","!mkdir /kaggle/working/images_to_parse\n","pdf_obj = pdfplumber.open(\"/kaggle/input/utilss/a.pdf\")\n","\n","for page in pdf_obj.pages:\n","    i=1\n","    images_in_page = page.images\n","    page_height = page.height\n","    for image in images_in_page:\n","        image_bbox = (image['x0'], page_height - image['y1'], image['x1'], page_height - image['y0'])\n","        cropped_page = page.crop(image_bbox)\n","        image_obj = cropped_page.to_image(resolution=400)\n","        image_obj.save(f\"/kaggle/working/images_to_parse/{image['page_number']}_{i}.png\")\n","        i+=1"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T08:47:54.451478Z","iopub.status.busy":"2024-07-10T08:47:54.451106Z","iopub.status.idle":"2024-07-10T08:47:54.456251Z","shell.execute_reply":"2024-07-10T08:47:54.455073Z","shell.execute_reply.started":"2024-07-10T08:47:54.451448Z"},"trusted":true},"outputs":[],"source":["page = pdf_obj.pages[10]\n","page.extract_table()"]},{"cell_type":"markdown","metadata":{},"source":["# ---------------------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{},"source":["# ----------------------------------------JUNK---------------------------------------------------"]},{"cell_type":"markdown","metadata":{},"source":["# -----------------------------------------------------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Split your document into big chunks\n","parent_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=50)\n","\n","# This text splitter is used to create the child documents. They should be small chunk size.\n","child_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=10)\n","\n","# # Split it up\n","child_chunks = child_splitter.split_documents(docs)\n","print (f\"Your document has been split into {len(child_chunks)} chunks\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# The vectorstore to use to index the child chunks\n","child_vectorstore = Chroma(\n","    collection_name=\"parent_document_splits\",\n","    embedding_function=embeddings_model\n",")\n","\n","# The storage layer for the parent documents\n","parent_docstore = InMemoryStore()\n","\n","retriever_parent = ParentDocumentRetriever(\n","    vectorstore=child_vectorstore, \n","    docstore=parent_docstore,\n","    child_splitter=child_splitter,\n","    parent_splitter=parent_splitter)\n","\n","retriever_parent.add_documents(docs)\n","\n","\n","num_parent_docs = len(retriever_parent.docstore.store.items())\n","num_child_docs = len(set(retriever_parent.vectorstore.get()['documents']))\n","\n","print (f\"You have {num_parent_docs} parent docs and {num_child_docs} child docs\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define the human message prompt template\n","human_message_template = PromptTemplate.from_template(\n","    \"\"\"\n","    You are an experienced assistant specializing in question-answering tasks. \n","    Utilize the provided context to respond to the question. \n","    Never provide an answer you are unsure about and ensure it is concise.\n","    Your answer must be comprehensive and contain all of the available details in the Context.\n","    \\nQuestion: {question} \\nContext: {context} \\nAnswer:\n","    \"\"\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def query_engine(query):\n","    # Create a HumanMessagePromptTemplate instance using the defined prompt template\n","    human_message_prompt_template = HumanMessagePromptTemplate(prompt=human_message_template)\n","\n","    # Create the ChatPromptTemplate with the input variables and messages, excluding metadata\n","    chat_prompt_template = ChatPromptTemplate(\n","        input_variables=['context', 'question'],\n","        messages=[human_message_prompt_template]\n","    )\n","    gpt = AzureChatOpenAI(temperature=0, model_name=\"GPT35-turboA\", api_key=os.getenv('AZURE_OPENAI_API_KEY'),openai_api_version=\"2024-02-01\")\n","\n","    rag_chain = chat_prompt_template | gpt | StrOutputParser()\n","    #question = 'Summary the provided context'\n","    question = query\n","    child_docs = child_vectorstore.similarity_search(question)\n","    parent_relevant_docs = retriever_parent.invoke(question)\n","    \n","    print (f\"Child docs found: {len(child_docs)} \") \n","    print (f\"Parent docs retrieved: {len(parent_relevant_docs)}\")\n","    \n","    context= \"\"\n","    if parent_relevant_docs:\n","        for x in parent_relevant_docs:\n","            context+=x.page_content+\"\\n\\n\"\n","    else:\n","        for x in child_docs:\n","            context+=x.page_content+\"\\n\\n\"\n","    \n","    generation = rag_chain.invoke({\"context\": context, \"question\": question})\n","    return context,generation\n","    "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5351819,"sourceId":8902768,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
